{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Alphabet_5CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishnavipatil29/Sign-Language-Recognition/blob/main/Static%20Gesture%20Detection/Alphabet_5CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "1VkqYZpuTYkp",
        "outputId": "b325871b-2784-4084-d806-9fbfc8012573"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(5) \n",
        "import tensorflow as tf\n",
        "#tf.set_random_seed(2)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dir = '../input/asl-alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "eval_dir = '../input/asl-alphabet/asl_alphabet_test/asl_alphabet_test'\n",
        "\n",
        "\n",
        "#2. Loading the data\n",
        "#Helper function to load images from given directories\n",
        "def load_images(directory,uniq_labels):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for idx, label in enumerate(uniq_labels):\n",
        "        if (directory == train_dir):\n",
        "            for file in os.listdir(directory + \"/\" + label):\n",
        "                filepath = directory + \"/\" + label + \"/\" + file\n",
        "                #image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
        "                image = cv2.imdecode(np.fromfile(filepath, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                image = cv2.resize(image, (64, 64))\n",
        "                images.append(image)\n",
        "                labels.append(idx)\n",
        "        else:\n",
        "            filepath = directory + \"/\" + label \n",
        "            #image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
        "            image = cv2.imdecode(np.fromfile(filepath, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.resize(image, (64, 64))\n",
        "            images.append(image)\n",
        "            labels.append(idx)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return(images, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqXbdDyKTYk3"
      },
      "source": [
        "CATEGORIES = sorted(os.listdir(train_dir))\n",
        "#read images in train folder\n",
        "images, labels = load_images(directory = train_dir, uniq_labels = CATEGORIES)\n",
        "#read images in test folder\n",
        "X_eval, y_eval = load_images(directory = eval_dir, uniq_labels = sorted(os.listdir(eval_dir)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I4nW4MmTYk4",
        "outputId": "1a80db5f-62d6-4df0-b028-6bbb04ce49f2"
      },
      "source": [
        "#split data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1, stratify = labels)\n",
        "\n",
        "n = len(sorted(os.listdir(train_dir)))\n",
        "train_n = len(X_train)\n",
        "test_n = len(X_test)\n",
        "eval_n = len(X_eval)\n",
        "\n",
        "print(\"Total number of symbols: \", n)\n",
        "print(\"Number of training images: \" , train_n)\n",
        "print(\"Number of testing images: \", test_n)\n",
        "print(\"Number of evaluation images: \", eval_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of symbols:  29\n",
            "Number of training images:  78300\n",
            "Number of testing images:  8700\n",
            "Number of evaluation images:  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIn9MOwNTYk4",
        "outputId": "0ba71539-add4-414f-dcef-2b4b633795fe"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(78300, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9whBzy-CTYk5"
      },
      "source": [
        "#preprocessing\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "y_eval = keras.utils.to_categorical(y_eval)\n",
        "\n",
        "X_train = X_train.astype('float32')/255.0\n",
        "X_test = X_test.astype('float32')/255.0\n",
        "X_eval = X_eval.astype('float32')/255.0\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W541MhgOTYk6"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "#build the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', input_shape = (64, 64, 1)))\n",
        "model.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(filters = 256 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(29, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZybRjv2nTYk7",
        "outputId": "5edad7f0-b9c0-4679-c12a-cd047158da46"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 64)        1664      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29)                118813    \n",
            "=================================================================\n",
            "Total params: 1,657,053\n",
            "Trainable params: 1,657,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignVw6MHTYk7",
        "outputId": "589cbc8a-0dfa-4084-8e8f-bb5b20dd59e4"
      },
      "source": [
        "#compil the model\n",
        "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "#fit the model\n",
        "hist = model.fit(X_train, y_train, epochs = 5, batch_size = 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "78300/78300 [==============================] - 34s 430us/step - loss: 1.4009 - accuracy: 0.5721\n",
            "Epoch 2/5\n",
            "78300/78300 [==============================] - 29s 372us/step - loss: 0.2246 - accuracy: 0.9267\n",
            "Epoch 3/5\n",
            "78300/78300 [==============================] - 30s 377us/step - loss: 0.1369 - accuracy: 0.9587\n",
            "Epoch 4/5\n",
            "78300/78300 [==============================] - 29s 372us/step - loss: 0.1121 - accuracy: 0.9679\n",
            "Epoch 5/5\n",
            "78300/78300 [==============================] - 30s 377us/step - loss: 0.1016 - accuracy: 0.9729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvnrkTtVTYk7"
      },
      "source": [
        "#save model\n",
        "model.save('ASLGray.model')\n",
        "\n",
        "#load model\n",
        "model=tf.keras.models.load_model('ASLGray.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbMqBgeDTYk8",
        "outputId": "075ca54e-d388-45a5-f43e-1dad874a1b27"
      },
      "source": [
        "#Download model from kaggle\n",
        "from IPython.display import FileLink\n",
        "FileLink('ASLGray.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<a href='ASLGray.model' target='_blank'>ASLGray.model</a><br>"
            ],
            "text/plain": [
              "/kaggle/working/ASLGray.model"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8tOpkxMTYk8",
        "outputId": "3ef2992f-8d67-4639-c090-2cdfc1b77a92"
      },
      "source": [
        "#Accuracy of model\n",
        "score = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
        "print('Accuracy for test images:', round(score[1]*100, 3), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for test images: 99.816 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO8YgeQpTYk9"
      },
      "source": [
        "#prepare image to prediction\n",
        "def prepare(filepath):\n",
        "    image = cv2.imdecode(np.fromfile(filepath, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = cv2.resize(image, (64, 64))\n",
        "    image=image.reshape(-1, 64, 64, 1)\n",
        "    image=image.astype('float32')/255.0\n",
        "    return  image\n",
        "\n",
        "#use this function to predict images\n",
        "def predict(my_model, filepath):\n",
        "    prediction = model.predict([prepare(filepath)]) \n",
        "    category = np.argmax(prediction[0])\n",
        "    return  CATEGORIES[category]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8AxSBpwTYk9",
        "outputId": "5ba86bcc-b64e-4fde-d03a-4d19460dc526"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/W/W2348.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: W\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4HmKB8PTYk9",
        "outputId": "cec87be8-078d-4564-d6d6-01e667a12183"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_train/asl_alphabet_train/L/L11.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: L\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-SHNfglTYlA",
        "outputId": "9dfdea9c-e5fe-4953-9407-6b711982cfaa"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/A_test.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsP12Wn2TYlB",
        "outputId": "66da5d18-5d04-4bbc-f91a-133d5c7f13f9"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/B_test.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUkLJya5TYlB",
        "outputId": "3f1d24a2-93ee-4717-ddb8-24fe48848a75"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/C_test.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a60rGe-TYlC",
        "outputId": "67d00f31-6ad8-4b83-b18f-15c3d9cea2d3"
      },
      "source": [
        "category = predict(model,'/kaggle/input/asl-alphabet/asl_alphabet_test/asl_alphabet_test/D_test.jpg')\n",
        "print(\"The image class is: \" + str(category))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image class is: D\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}